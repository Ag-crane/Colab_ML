{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMyUNdz9PDkbFOI6IiMPZRQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"697304d0","executionInfo":{"status":"ok","timestamp":1670587897787,"user_tz":-540,"elapsed":9185,"user":{"displayName":"eh L","userId":"05502699333303135407"}}},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from sklearn import tree\n","from sklearn import svm\n","\n","from keras.datasets import mnist\n","\n","# 손글씨 이미지 데이터셋 784 x 1짜리 벡터로 변환 = 28 x 28 pixel로 이루어진 손글씨 이미지\n","((x_train, y_train), (x_test, y_test)) = mnist.load_data()\n","\n","X_train = x_train.reshape(-1,28*28)\n","X_test = x_test.reshape(-1,28*28)\n","\n","N_train,D = X_train.shape\n","N_test,D = X_test.shape\n","\n","# dimensional reduction (PCA) : 시간 단축하려고\n","# covariance\n","mu = np.mean(X_train, axis = 0)\n","C = X_train - mu\n","C = (1/N_train) * C.T.dot(C)\n","\n","# SVD: C = U*S*V^T\n","U, s, V = np.linalg.svd(C, full_matrices = True)\n","S = np.diag(s)\n","V = V.T\n","\n","# 전체 입력 차원 784 중에서, 차원을 축소해서 사용\n","D_reduce = 30\n","X_train = X_train.dot(V[:,0:D_reduce]) # N_train x D_reduce\n","X_test = X_test.dot(V[:,0:D_reduce]) # N_train x D_reduce\n","\n","X_train = np.hstack([np.ones((N_train,1)),X_train])\n","X_test = np.hstack([np.ones((N_test,1)),X_test])\n","\n","# one-of-K coding\n","num = np.unique(y_train, axis = 0)\n","num = num.shape[0]\n","\n","t_train = np.eye(num)[y_train]\n","t_test = np.eye(num)[y_test]"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"76c7fb1a","outputId":"a9028a72-4bfc-4420-d3b2-95eda8fa222c","executionInfo":{"status":"ok","timestamp":1670587897788,"user_tz":-540,"elapsed":5,"user":{"displayName":"eh L","userId":"05502699333303135407"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["(31, 100)\n","(100, 1000)\n","(1000, 10)\n"]}],"source":["# parameter\n","M = np.array([X_train.shape[1],100,1000,10])  # layer별 뉴런 개수. 시작은 input+1(bias), 마지막은 클래스 개수\n","L = M.shape[0] - 1   # layer 수  \n","\n","eta = 1e-5\n","maxEpoch = 30\n","\n","# initialize parameter\n","# W[0] = 31 x 100\n","# W[1] = 100 x 1000\n","# W[2] = 1000 x 10\n","W = []\n","\n","for l in range(L):\n","    W.append(np.random.randn(M[l],M[l + 1]))\n","    print(W[l].shape)\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"4277251d","executionInfo":{"status":"ok","timestamp":1670587899911,"user_tz":-540,"elapsed":2126,"user":{"displayName":"eh L","userId":"05502699333303135407"}}},"outputs":[],"source":["# activation function\n","def act(x):        # activation func \n","    return np.tanh(x)\n","\n","def dact(x):       # 도함수\n","    return 1 - np.tanh(x)**2\n","\n","# softmax\n","def softmax(x):    \n","    \n","    if x.ndim == 1:\n","        f_x = np.exp(x)\n","        return f_x / np.sum(f_x)\n","    \n","    elif x.ndim == 2:\n","        max = np.max(x,axis = 1,keepdims = True)\n","        e_x = np.exp(x - max)\n","        sum = np.sum(e_x,axis = 1,keepdims = True)\n","        f_x = e_x / sum \n","        return f_x\n","\n","# cross entropy\n","def cross_entropy(y,t):\n","    N,K = y.shape\n","    e = np.sum(- t * np.log(y), axis = 1)\n","    e = np.mean(e)\n","    \n","    return e\n","\n","cost = []\n","accuracy = []\n","\n","# initialize for a single input\n","\n","# forward propagation\n","# 뉴런 개수만큼\n","z_sample = []\n","a_sample = []\n","for l in range(L):    \n","    z_sample.append(np.zeros((1,M[l + 1])))\n","    a_sample.append(np.zeros((1,M[l + 1])))    \n","pred_sample = softmax(z_sample[-1])   # output y  \n","\n","# backpropagation\n","delta = []\n","for l in np.arange(L):    \n","    delta.append(np.zeros((M[l],1)))\n","        \n","# initialize for entire inputs\n","# forward propagation\n","z_train = []\n","a_train = []\n","for l in range(L):     # N개 한번에 계산할 준비  \n","    z_train.append(np.zeros((N_train,M[l + 1])))\n","    a_train.append(np.zeros((N_train,M[l + 1])))    \n","pred_train = softmax(z_train[-1])    "]},{"cell_type":"code","source":[],"metadata":{"id":"w08CIDzfn1Y4","executionInfo":{"status":"ok","timestamp":1670587899911,"user_tz":-540,"elapsed":5,"user":{"displayName":"eh L","userId":"05502699333303135407"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["print(N_train)\n","print(X_train.shape)\n","print(t_train.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OPescdVtqsst","executionInfo":{"status":"ok","timestamp":1670587899912,"user_tz":-540,"elapsed":5,"user":{"displayName":"eh L","userId":"05502699333303135407"}},"outputId":"14f30324-f631-4b60-c013-be271f64fac1"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["60000\n","(60000, 31)\n","(60000, 10)\n"]}]},{"cell_type":"code","execution_count":14,"metadata":{"id":"floppy-wallpaper","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670589175314,"user_tz":-540,"elapsed":293074,"user":{"displayName":"eh L","userId":"05502699333303135407"}},"outputId":"4f6884a4-f249-4583-f45e-460ccf792568"},"outputs":[{"output_type":"stream","name":"stdout","text":["[epoch 0] cross entropy: 21.8277, accuracy: 0.3401\n","[epoch 1] cross entropy: 22.7977, accuracy: 0.3675\n","[epoch 2] cross entropy: 20.6565, accuracy: 0.4612\n","[epoch 3] cross entropy: 15.9617, accuracy: 0.4688\n","[epoch 4] cross entropy: 17.4357, accuracy: 0.4699\n","[epoch 5] cross entropy: 17.3424, accuracy: 0.4886\n","[epoch 6] cross entropy: 17.7095, accuracy: 0.5125\n","[epoch 7] cross entropy: 12.9236, accuracy: 0.5585\n","[epoch 8] cross entropy: 12.9759, accuracy: 0.5756\n","[epoch 9] cross entropy: 9.6258, accuracy: 0.6413\n","[epoch 10] cross entropy: 8.5523, accuracy: 0.6338\n","[epoch 11] cross entropy: 8.6640, accuracy: 0.6543\n","[epoch 12] cross entropy: 8.8188, accuracy: 0.6432\n","[epoch 13] cross entropy: 11.7133, accuracy: 0.5984\n","[epoch 14] cross entropy: 12.4564, accuracy: 0.6486\n","[epoch 15] cross entropy: 7.6835, accuracy: 0.6750\n","[epoch 16] cross entropy: 9.5544, accuracy: 0.6489\n","[epoch 17] cross entropy: 8.5629, accuracy: 0.6863\n","[epoch 18] cross entropy: 7.7480, accuracy: 0.6767\n","[epoch 19] cross entropy: 10.5663, accuracy: 0.6512\n","[epoch 20] cross entropy: 10.8833, accuracy: 0.6486\n","[epoch 21] cross entropy: 11.4833, accuracy: 0.6207\n","[epoch 22] cross entropy: 13.5174, accuracy: 0.6359\n","[epoch 23] cross entropy: 9.9944, accuracy: 0.6710\n","[epoch 24] cross entropy: 6.7380, accuracy: 0.7192\n","[epoch 25] cross entropy: 6.3235, accuracy: 0.7230\n","[epoch 26] cross entropy: 6.5000, accuracy: 0.7190\n","[epoch 27] cross entropy: 6.2480, accuracy: 0.7296\n","[epoch 28] cross entropy: 7.2741, accuracy: 0.7113\n","[epoch 29] cross entropy: 7.6960, accuracy: 0.7090\n"]}],"source":["# batch gradient descent\n","for epoch in range(maxEpoch):  \n","          \n","    W_new = W\n","    \n","    ### forward propagation\n","    # input layer\n","    z_sample[0] = X_train.dot(W[0])    # 60000x31 dot 31x100 = 60000x100\n","    a_sample[0] = act(z_sample[0])     # 60000x100\n","    \n","    # 나머지 layer\n","    for l in range(L - 1):    \n","        z_sample[l + 1] = a_sample[l].dot(W[l + 1])   \n","        a_sample[l + 1] = act(z_sample[l + 1])        \n","\n","    # output layer\n","    pred_sample = softmax(z_sample[-1])      \n","\n","    ### backpropagation : 각 layer마다 delta, parameter 구함\n","    # output layer\n","    delta[L - 1] = -(t_train - pred_sample)  # local gradient    \n","\n","    # propagation\n","    for l in np.arange(L - 1,1,-1):\n","        delta[l - 1] = W[l].dot(delta[l].T).T * dact(z_sample[l - 1])         \n","    \n","    # input layer        \n","    delta[0] = W[1].dot(delta[1].T).T * dact(z_sample[0]) \n","\n","    ### update\n","    W_new[L - 1] = W_new[L - 1] - eta*a_sample[L - 2].T.dot(delta[L - 1])\n","    for l in np.arange(L - 1,1,-1):   \n","        W_new[l - 1] = W_new[l - 1] - eta*a_sample[l - 2].T.dot(delta[l - 1])  \n","    # 마지막은 a 대신 x\n","    W_new[0] = W_new[0] - eta*X_train.T.dot(delta[0])  \n","    \n","    W = W_new\n","\n","    # forward propagation\n","    z_train[0] = X_train.dot(W[0])\n","    a_train[0] = act(z_train[0])\n","\n","    for l in range(L - 1):    \n","        z_train[l + 1] = a_train[l].dot(W[l + 1])\n","        a_train[l + 1] = act(z_train[l + 1])\n","\n","    pred_train = softmax(z_train[-1])\n","\n","    # performance\n","    cost.append(cross_entropy(pred_train,t_train))\n","    accuracy.append(np.sum(y_train == np.argmax(pred_train, axis = 1)) / N_train)\n","    \n","    print('[epoch %d] cross entropy: %.4f, accuracy: %.4f'%(epoch,cost[-1],accuracy[-1]))     "]}]}